<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Grace">
<meta name="dcterms.date" content="2025-02-07">
<meta name="description" content="Do LLMs know how much water they use?">

<title>The environmental impact of generative AI – Grace’s LLM Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-d75320580429fd03ccc14abf5aea7e44.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Grace’s LLM Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/grace-kneidel"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The environmental impact of generative AI</h1>
                  <div>
        <div class="description">
          Do LLMs know how much water they use?
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">prompting</div>
                <div class="quarto-category">comparing models</div>
                <div class="quarto-category">environment</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Grace </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 7, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Lots of people, myself included, have some concerns about using LLMs because they are so resource intensive. Today, I figured I would test AI’s own awareness of its water needs and compare them to the current estimates. I’m going to vary this across different models that have different knowledge cutoffs to see how the responses vary. New work on the water use of generative AI could have happened since these models were trained, so I’m hoping we will see some cool variation.</p>
<section id="the-test" class="level2">
<h2 class="anchored" data-anchor-id="the-test">The test</h2>
<section id="part-1-gpt-4o" class="level3">
<h3 class="anchored" data-anchor-id="part-1-gpt-4o">Part 1: gpt-4o</h3>
<div id="ff4422d9-449d-4b72-807f-4f8f06853510" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown, display</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load API key</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> load_dotenv()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="50685982-7dde-480e-a228-ebf33154b888" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="st">"gpt-4o"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>system_role <span class="op">=</span> <span class="st">"You are a reporter for The Economist covering environmental economics. Give your responses in Markdown format."</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>initial_prompt <span class="op">=</span> <span class="st">'''First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use </span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="st">per single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="st">use the most recent scientific estimates and cite your sources.'''</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: system_role} ,</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: initial_prompt},</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># {"role": "assistant", "content": "" },</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># {"role": "user", "content": "" }</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>completion <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  model<span class="op">=</span>model,        <span class="co"># the model to use </span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  messages<span class="op">=</span>messages,  <span class="co"># a list of dictionaries with the prompt</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>  n<span class="op">=</span><span class="dv">3</span>,                <span class="co"># how many responses to generate</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  temperature<span class="op">=</span><span class="fl">0.7</span>     <span class="co"># temperature parameter</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> completion.choices[<span class="dv">0</span>].message.content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="849cc5ec-0e26-4e96-a31b-4a60314f24ab" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-tags="[]" data-execution_count="12">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> rnum, resp <span class="kw">in</span> <span class="bu">enumerate</span>(completion.choices,<span class="dv">1</span>): </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    display(Markdown(<span class="ss">f'-----</span><span class="ch">\n</span><span class="ss">#### Response </span><span class="sc">{</span>rnum<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>resp<span class="sc">.</span>message<span class="sc">.</span>content<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-1" class="level4">
<h4 class="anchored" data-anchor-id="response-1">Response 1</h4>
<p><strong>Knowledge Cutoff:</strong> October 2023</p>
<p>The environmental impact of each large language model (LLM) query, specifically in terms of water usage, can be relatively small when compared to other daily activities. According to recent estimates, processing a single LLM query can consume approximately 0.001 liters of water, accounting for the water used in cooling data centers and powering the necessary computing infrastructure (Patterson et al., 2023). In contrast, activities like brushing your teeth with the tap running can use around 7.5 to 15 liters of water per session (U.S. EPA). This comparison indicates that a single LLM query has a significantly lower water footprint than such common water-intensive activities. Nonetheless, as the use of LLMs scales globally, their cumulative environmental impact becomes more pronounced. This underscores the importance of optimizing data center efficiency and exploring sustainable practices in AI development to mitigate broader environmental effects.</p>
<p><strong>Sources:</strong> - Patterson, D., et al.&nbsp;(2023). “The Carbon Footprint of Machine Learning.” Proceedings of the Conference on Machine Learning and Climate Change. - U.S. Environmental Protection Agency (EPA). “WaterSense: Brushing Your Teeth.” <a href="https://www.epa.gov/watersense">EPA.gov</a></p>
</section>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-2" class="level4">
<h4 class="anchored" data-anchor-id="response-2">Response 2</h4>
<p><strong>Knowledge Cutoff:</strong> October 2023</p>
<p>The environmental impact of a single Large Language Model (LLM) query, such as those processed by cutting-edge AI systems, primarily revolves around energy consumption and associated carbon emissions rather than direct water usage. The energy required for a single LLM query is typically measured in terms of kilowatt-hours (kWh), which indirectly relates to water usage through the cooling processes of data centers and energy production. According to recent estimates, each LLM query consumes approximately 0.0003 kWh of energy (Strubell et al., 2019). In comparison, brushing your teeth with water running for two minutes uses about 4 gallons (15.1 liters) of water (EPA, 2023). While the exact water footprint of a single LLM query is difficult to quantify in isolation due to variations in data center efficiencies and energy grids, it is substantially less direct than the tangible water usage involved in daily activities like tooth brushing. However, as LLM utilization scales globally, the cumulative environmental impact becomes significant, prompting calls for more sustainable AI practices and energy sources.</p>
</section>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-3" class="level4">
<h4 class="anchored" data-anchor-id="response-3">Response 3</h4>
<p><strong>Knowledge Cutoff:</strong> October 2023</p>
<p>The environmental impact of each Large Language Model (LLM) query is primarily associated with the energy consumption required to power the data centers that host these models. Recent estimates suggest that a single query to an LLM consumes approximately 0.0003 kWh of energy, which translates to a very small carbon footprint. In terms of water usage, this energy consumption indirectly reflects water use, as water is often used for cooling data centers. According to a study by Strubell et al.&nbsp;(2019), the water footprint for a single AI query is quite minimal, comparable to a few milliliters of water. To provide context, brushing your teeth with the tap running can use around 7.5 liters of water per minute. Thus, the water footprint of an LLM query is vastly smaller. However, when scaled up to millions of queries, the cumulative impact becomes significant, highlighting the importance of developing more energy-efficient algorithms and infrastructure (Strubell et al., 2019; Google AI, 2021).</p>
<p><strong>Sources:</strong></p>
<ul>
<li>Strubell, E., Ganesh, A., &amp; McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. <em>arXiv preprint arXiv:1906.02243</em>.</li>
<li>Google AI Blog (2021). Our commitment to sustainability through AI. <a href="https://ai.googleblog.com/2021/05/our-commitment-to-sustainability.html">Link</a></li>
</ul>
</section>
</div>
</div>
<p>Wow! These estimates vary a lot, from 0.5 liters to 0.0005 liters.</p>
</section>
<section id="part-2-gpt-3.5-turbo" class="level3">
<h3 class="anchored" data-anchor-id="part-2-gpt-3.5-turbo">Part 2: gpt-3.5-turbo</h3>
<div id="8bc511ec-7d98-4ba2-abae-25f0d1326520" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: system_role} ,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: initial_prompt},</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># {"role": "assistant", "content": "" },</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># {"role": "user", "content": "" }</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>completion <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  model<span class="op">=</span>model,        <span class="co"># the model to use </span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  messages<span class="op">=</span>messages,  <span class="co"># a list of dictionaries with the prompt</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  n<span class="op">=</span><span class="dv">3</span>,                <span class="co"># how many responses to generate</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  temperature<span class="op">=</span><span class="fl">0.7</span>     <span class="co"># temperature parameter</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> completion.choices[<span class="dv">0</span>].message.content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="64ceb84b-9949-45e9-b173-b8850c060d41" class="cell" data-editable="true" data-slideshow="{&quot;slide_type&quot;:&quot;&quot;}" data-tags="[]" data-execution_count="14">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> rnum, resp <span class="kw">in</span> <span class="bu">enumerate</span>(completion.choices,<span class="dv">1</span>): </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    display(Markdown(<span class="ss">f'-----</span><span class="ch">\n</span><span class="ss">#### Response </span><span class="sc">{</span>rnum<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>resp<span class="sc">.</span>message<span class="sc">.</span>content<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-1-1" class="level4">
<h4 class="anchored" data-anchor-id="response-1-1">Response 1</h4>
<p>Knowledge cutoff: October 2021</p>
<ol type="1">
<li>Query: “How much water is used to produce one pound of beef?”</li>
</ol>
<p>The environmental impact of producing one pound of beef is significant in terms of water usage. According to recent studies, it is estimated that approximately 1,799 gallons of water are required to produce one pound of beef, taking into account water used for feed production, drinking water for the animals, and processing. This high water usage is mainly attributed to the water-intensive nature of growing feed crops for livestock and providing water for the animals throughout their life cycle. To put this into perspective, the water used to produce one pound of beef is roughly equivalent to the amount of water an average person would use for brushing their teeth daily for over two and a half years.</p>
<p>Sources: - Mekonnen, M.M. and Hoekstra, A.Y. (2012). A Global Assessment of the Water Footprint of Farm Animal Products. Ecosystems, 15(3), 401-415.</p>
<ol start="2" type="1">
<li>Query: “How much water is used to produce one cotton t-shirt?”</li>
</ol>
<p>The environmental impact of producing one cotton t-shirt in terms of water usage is substantial. Recent data suggests that approximately 713 gallons of water are needed to produce one cotton t-shirt, accounting for water used in growing cotton plants, processing the fibers, and dyeing the fabric. The water footprint of cotton production is particularly high due to the crop’s demand for irrigation and the water-intensive processes involved in turning raw cotton into a finished garment. To provide context, the water used to make one cotton t-shirt is equivalent to the amount of water an individual would use for brushing their teeth daily for almost 4 years.</p>
<p>Sources: - Mekonnen, M.M. and Hoekstra, A.Y. (2011). The Green, Blue and Grey Water Footprint of Crops and Derived Crop Products. Hydrology and Earth System Sciences, 15(5), 1577-1600.</p>
</section>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-2-1" class="level4">
<h4 class="anchored" data-anchor-id="response-2-1">Response 2</h4>
<p>Knowledge cutoff: September 2021</p>
<ol type="1">
<li><p><strong>LLM query: “How much water is used to produce one almond?”</strong></p>
<p>The environmental impact of producing one almond is significant due to the high water intensity of almond cultivation. According to a study by the University of California, it takes approximately 1.1 gallons of water to produce a single almond. This is primarily because almond trees require a substantial amount of water to grow, especially in regions with arid climates where they are predominantly cultivated. To put this into context, producing one almond is equivalent to the amount of water used by brushing your teeth for about 10 minutes. The water footprint of almonds has raised concerns about the sustainability of almond farming, particularly in water-stressed regions like California where a large percentage of the world’s almonds are grown.</p></li>
<li><p><strong>LLM query: “How much water is used to produce one avocado?”</strong></p>
<p>The environmental impact of producing one avocado is also notable in terms of water usage. According to research published in the journal Water, it takes around 72 gallons of water to produce a single avocado. Avocado trees are known to be water-intensive crops, requiring significant irrigation to support their growth and yield. To put this in perspective, the water footprint of one avocado is equivalent to the amount of water used by brushing your teeth for approximately 170 times. This highlights the substantial water footprint of avocados and underscores the importance of considering the environmental impact of consuming water-intensive foods like avocados, especially in regions facing water scarcity challenges.</p></li>
<li><p><strong>LLM query: “How much water is used to produce one pound of beef?”</strong></p>
<p>The environmental impact of producing one pound of beef is notably high in terms of water consumption. According to a report by the Water Footprint Network, it takes approximately 1,800 gallons of water to produce one pound of beef. This is primarily due to the water needed for livestock drinking, irrigation of animal feed crops, and meat processing. To provide context, the water footprint of one pound of beef is equivalent to the amount of water used by brushing your teeth for about 3,600 times. The substantial water footprint of beef production has raised concerns about the sustainability of meat consumption, particularly as global demand for animal products continues to rise and water resources become increasingly strained.</p></li>
</ol>
</section>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#### Response 3 Knowledge cutoff: September 2021</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#### Response 1 <strong>My knowledge cutoff is October 2023.</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Recent studies indicate that while the training phase of large language models (LLMs) is highly energy intensive, the inference phase—i.e.&nbsp;processing a single query—generally consumes only a few milli‐kilowatt‐hours, resulting in an extremely modest direct water footprint when considering data center cooling. For instance, estimates suggest that generating 1 kWh of electricity in thermoelectric plants may involve roughly 2–3 liters of water (U.S. Environmental Protection Agency, 2019)[1]; thus, an inference operation consuming around 0.001 kWh might indirectly “use” only about 0.002–0.003 liters of water. In comparison, a typical tooth brushing episode may use 2–3 liters of water (Hoekstra et al., 2011)[2], which puts the water intensity of a single LLM query into stark perspective. Although the cumulative environmental impact of millions of such queries should not be overlooked, on an individual basis the direct water usage is negligible relative to everyday activities like brushing your teeth.</td>
</tr>
</tbody>
</table>
<p>[1] U.S. Environmental Protection Agency. (2019). Water Use in Electricity Production.<br>
[2] Hoekstra, A. Y., et al.&nbsp;(2011). The Water Footprint Assessment Manual. UNESCO.</p>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-2-2" class="level4">
<h4 class="anchored" data-anchor-id="response-2-2">Response 2</h4>
<p><strong>Knowledge Cutoff:</strong> October 2023</p>
<p>Recent studies indicate that while the energy consumption—and hence the indirect water usage via cooling—of large language model (LLM) queries is not negligible at scale, the water footprint per individual query is extremely small compared to everyday water-intensive activities. Data centers commonly use water-cooled systems to manage heat generated by servers, and estimates suggest that a single query could be responsible for the equivalent of only a few milliliters of water usage when averaged over billions of queries (see, for example, analyses in the work by Patterson et al.&nbsp;(2021) and reports from the Uptime Institute). In contrast, everyday activities like brushing your teeth typically involve running taps that dispense roughly 2 liters of water per minute—so a two-minute brushing session easily uses around 4 liters of water. Thus, while LLM queries do contribute to a data center’s overall environmental impact (through both energy consumption and the associated water use for cooling), the water cost per individual query is orders of magnitude lower than that of a simple daily habit, highlighting the benefits of operational efficiencies realized at scale.</p>
<p><strong>Sources:</strong><br>
- Patterson, D., et al.&nbsp;(2021). “Energy and Policy Considerations for Deep Learning in NLP.”<br>
- Uptime Institute Reports on Data Center Water Usage.<br>
- U.S. EPA Guidelines on Residential Water Use.</p>
</section>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<hr>
<section id="response-3-1" class="level4">
<h4 class="anchored" data-anchor-id="response-3-1">Response 3</h4>
<p><strong>Knowledge Cutoff:</strong> My knowledge cutoff is October 2023.</p>
<p>A single LLM query—such as one processed by a large language model like ChatGPT—is estimated to consume on the order of 0.01 kilowatt-hours (kWh) or less in electricity, with the associated water usage for data center cooling being spread thinly across millions of queries. Modern data centers, which may require roughly 1.8 liters of water per kWh for cooling (according to estimates from sources like the Uptime Institute and research from the Lawrence Berkeley National Laboratory), translate this energy consumption into only a few milliliters of water per query. In contrast, a typical toothbrushing session uses about 2 to 4 liters of water (Water Research Foundation, 2020), highlighting that while the environmental impact per individual LLM query is modest—especially in terms of water use—the aggregated effect of billions of queries can become significant in energy demand and resource consumption. Such comparisons underscore the importance of advancing energy and water-efficient data center operations as digital tasks increasingly scale in our internet-driven world (Strubell et al., 2019; Patterson et al., 2021).</p>
</section>
</div>
</div>
<p>Interesting how these cite primarily the EPA and papers from many years ago.</p>
</section>
<section id="so-whats-the-correct-answer" class="level3">
<h3 class="anchored" data-anchor-id="so-whats-the-correct-answer">So what’s the <em>correct</em> answer?</h3>
<p>There is none, and that’s part of why I thought this exercise was fun.</p>
<p>One <a href="https://e360.yale.edu/features/artificial-intelligence-climate-energy-emissions">study</a> from Yale in February 2024 suggests that “a person who engages in a session of questions and answers with GPT-3 (roughly 10 to 50 responses) drives the consumption of a half-liter of fresh water”.</p>
<p>So if we do the math based on this one estimate, each query is somewhere between 0.05 and 0.01 liters of water. But this may vary a lot for other LLM models, too. It seems that the models with later knowledge cutoffs (gpt-4o and o3-mini) were much better at understanding this.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/grace-kneidel\.github\.io\/comm4190_S25_Using_LLMs_Blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>