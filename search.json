[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "How well can AI move from one coding language to another?\n\n\n\n\n\n\nStata\n\n\nR\n\n\ntranslation\n\n\n\nIt seems to depend a lot on the language\n\n\n\n\n\nFeb 15, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\n\n\n\n\n\n\nThe environmental impact of generative AI\n\n\n\n\n\n\nprompting\n\n\ncomparing models\n\n\nenvironment\n\n\n\nDo LLMs know how much water they use?\n\n\n\n\n\nFeb 7, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT help me open the correct PDF?\n\n\n\n\n\n\nprompting\n\n\n\nIt turns out to be quite the challenge.\n\n\n\n\n\nFeb 1, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/translation_stata_r.html",
    "href": "posts/translation_stata_r.html",
    "title": "How well can AI move from one coding language to another?",
    "section": "",
    "text": "The art of (code) translation\nAs someone who works with a lot of data, I’ve noticed that sometimes certain coding languages are better suited towards specific tasks. On the other hand, projects can get more complicated when several scripts in several languages are involved, especially if not everybody on the team has the same amount of familiarity with each language.\n\nThe goal today is to do an excercise with coding languages inspired by Chapter 3 of Prompt Engineering for Generative AI (Phoenix and Taylor 2024). The authors ask an LLM to create simple text in English. Then, they “Now make the text incredibly complex and hard to read.”. They ask AI to translate this complicated English text into simple Spanish text. Finally, they ask for the Spanish to be translated back into English and compare the output with the simple English text that the exercise began with. They find that LLMs do pretty well at this and attribute much of that success to the fact that Spanish and English texts are both widely available online.\n\n\nSteps of this experiment\n\n\n\n\n\nflowchart LR\n  A[1. Generate simple Stata code] --&gt; B[2. Make it harder to understand]\n  B --&gt; C[3. Translate to R in the simplest way possible]\n  C --&gt; D[4. Translate back to Stata]\n\n\n\n\n\n\nI’d like to avoid loading specific datasets into Stata and R, so I am going to prompt ChatGPT to build simple Stata code that involves drawing random numbers.\n\nStep 1: Generate simple Stata code\n\n\n\nOff to a good start\n\n\n\n\n\nLove the default colors!\n\n\n\n\nStep 2: Make it harder to understand\nNow, in the same chat window, I will ask a variation of what Phoenix and Taylor asked in their Spanish to English example: “Now make the code incredibly complex and hard to read. BUT, it still needs to be able to run!”\nChatGPT reported the following about its new code:\nWhat makes this code unnecessarily complicated: 1. Unnecessary local variables: Uses random operations like runiform and rnormal wrapped in local variables for no reason. 2. Confusing foreach and forval loops: Uses loops when they aren’t needed, just to replace values in a random manner. 3. Overuse of macros and complicated conditions: Involves checking macro lists, even though they aren’t required to generate the histogram. 4. Unnecessary graph twoway scatter: Adds a scatter plot for the same data, even though the task is to generate a histogram.\nWhile certainly overly complicated, this new code did not run. So I asked ChatGPT to try again. And again. I told it the errors that were appearing and got validating answers such as: - “Ah, I see the issue now! In Stata, you can’t use both the bin() and width() options together in the histogram command.” - “You’re right! I overlooked that once again. The issue is that Stata does not allow both bin() and width() to be used at the same time, so let’s adjust it to use one of those options correctly.”\nEventually, I gave up and just troubleshooted the code that it outputted myself. I think ChatGPT was getting really excited about making the code needlessly complex, so it kept trying to add ALL the graphing options when that wasn’t actually allowed.\n\n\n\nOur needlessly complicated Stata histogram\n\n\n\n\nStep 3: Translate to R in the simplest way possible\nTime to ask another variation of Phoenix and Taylor’s prompt. In the same window, I said:\nNow transform the Stata code into a simple, easy to read format that’s in R code , make sure that it is very easy to understand and read. You must ensure that it is as simple to comprehend as possible.\nChatGPT did great here. Easy breezy, our histogram is now in R.\n\n\n4. Translate back to Stata\nGiven how well ChatGPT did at translating this code to R, and given how simple the code is now, I expected that this would be a breeze.\nBut it wasn’t, because once again ChatGPT showed a lack of understanding of Stata image formatting commands! When I told it the error I was getting, I once again got a very affirming response:\nYou’re absolutely right! In Stata, the edgecolor() option is not available for histograms. To correct that and ensure the code runs smoothly, I’ll remove that option and simplify the command while keeping it easy to understand.\n\n\n\nNot quite a breeze\n\n\nAfter this correction, the code did run, but ChatGPT forgot to add the frequency option, so the data y axis shows the probability of each outcome from 0 to 0.5. But the y axis labels are still set to reflect frequency. It’s not a good look!\n\n\n\n\nConclusion\nWhile ChatGPT was capable of performing the basic code translation tasks, it needed a lot of correction. It seemed to be a lot less comfortable working with Stata than with R. It’s true that R is open source and Stata isn’t, but I expected better results because Stata has been around for a long time. For reference, ChatGPT tells me that the first official version of R was released in February 2000, while Stata 1.0 was released in 1985.\nWhen pressed about its relative amounts of training data, ChatGPT did confess that it had more access to R data- though who knows if that is the truth.\n\n\nA final note: I had never before seen the Stata command that kept throwing me errors from the AI-generated responses. As far as I can tell, this command, edgecolor, is exclusively found in MATLAB syntax!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/002_water.html",
    "href": "posts/002_water.html",
    "title": "The environmental impact of generative AI",
    "section": "",
    "text": "Lots of people, myself included, have some concerns about using LLMs because they are so resource intensive. Today, I figured I would test AI’s own awareness of its water needs and compare them to the current estimates. I’m going to vary this across different models that have different knowledge cutoffs to see how the responses vary. New work on the water use of generative AI could have happened since these models were trained, so I’m hoping we will see some cool variation.\n\nThe test\n\nPart 1: gpt-4o\n\nfrom openai import OpenAI\nimport os\nimport pandas as pd\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\n\n\nmodel = \"gpt-4o\"\nsystem_role = \"You are a reporter for The Economist covering environmental economics\"\ninitial_prompt = '''First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use \nper single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to \nuse the most recent scientific estimates and cite your sources.'''\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_role} ,\n    {\"role\": \"user\", \"content\": initial_prompt},\n    # {\"role\": \"assistant\", \"content\": \"\" },\n    # {\"role\": \"user\", \"content\": \"\" }\n]\n\n\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=model,        # the model to use \n  messages=messages,  # a list of dictionaries with the prompt\n  n=3,                # how many responses to generate\n  temperature=0.7     # temperature parameter\n)\n\nresponse = completion.choices[0].message.content\n\nprint(messages)\n\n[{'role': 'system', 'content': 'You are a reporter for The Economist covering environmental economics'}, {'role': 'user', 'content': 'First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use \\nper single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to \\nuse the most recent scientific estimates and cite your sources.'}]\n\n\n\nfor resp in completion.choices: \n    print(resp.message.content)\n    print('---')\n\nMy knowledge cutoff date is October 2023. \n\nThe environmental impact of each large language model (LLM) query, specifically in terms of water consumption, is relatively modest when compared to traditional water-intensive activities. Recent estimates suggest that a single LLM query consumes about 0.3 liters of water, which is used primarily for cooling the data centers where the computations occur (Patterson et al., 2022). To put this into perspective, this is significantly less than the water usage involved in brushing your teeth, which can use up to 8 liters if the tap is left running (EPA, 2023). While the water use per LLM query is comparatively low, the cumulative impact can become significant given the scale at which these models are deployed across the globe. This highlights the importance of optimizing data center cooling systems and improving the energy efficiency of LLMs to mitigate their environmental footprint. \n\nReferences:\n- Patterson, D. et al. (2022). 'Carbon Emissions and Large Neural Network Training'. \n- Environmental Protection Agency (EPA) (2023). 'WaterSense: Simple Ways to Save Water'.\n---\nMy knowledge cutoff is October 2023. The environmental impact of each query processed by large language models (LLMs), such as those used in AI chatbots, primarily involves energy consumption and its associated carbon emissions, rather than water usage. However, water is indirectly used in cooling the data centers where these models run. Recent studies suggest that a single LLM query can consume about 0.0003 kilowatt-hours (kWh) of electricity, equating to approximately 0.3 grams of CO2 emissions, depending on the energy mix used (Wu et al., 2023). In terms of water usage, a single query is estimated to indirectly require about 0.0005 liters of water, primarily for cooling purposes (Patterson et al., 2023). For context, brushing your teeth with the tap running can use approximately 7.5 liters of water per minute. Therefore, the water footprint of an LLM query is minuscule compared to such activities, highlighting the relatively low direct water demand of these digital interactions. However, as the use of AI continues to scale, the cumulative environmental impacts warrant attention and efforts to improve the sustainability of data centers.\n---\nMy knowledge cutoff date is October 2023.\n\nThe environmental impact of each Large Language Model (LLM) query primarily involves energy consumption, which indirectly contributes to water use, given that water is often used in electricity generation processes. Recent scientific estimates suggest that the carbon and water footprint of a single LLM query can vary significantly depending on the size of the model and the infrastructure efficiency. For instance, a single query on a large-scale LLM might consume approximately 0.5 liters of water, primarily due to the cooling requirements of data centers (Patterson et al., 2021). To put this into context, brushing your teeth with the tap running for two minutes uses about 6 liters of water, according to the U.S. Environmental Protection Agency. Therefore, while each LLM query represents a small fraction of the water usage of common daily activities, the cumulative impact can be substantial given the scale of LLM deployment and usage globally. It is crucial for data centers to adopt more sustainable energy and water usage practices to mitigate this impact.\n---\n\n\nWow! These estimates vary a lot, from 0.5 liters to 0.0005 liters.\n\n\nPart 2: gpt-3.5-turbo\n\nmodel = \"gpt-3.5-turbo\"\nsystem_role = \"You are a reporter for The Economist covering environmental economics\"\ninitial_prompt = '''First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use \nper single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to \nuse the most recent scientific estimates and cite your sources.'''\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_role} ,\n    {\"role\": \"user\", \"content\": initial_prompt},\n    # {\"role\": \"assistant\", \"content\": \"\" },\n    # {\"role\": \"user\", \"content\": \"\" }\n]\n\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=model,        # the model to use \n  messages=messages,  # a list of dictionaries with the prompt\n  n=3,                # how many responses to generate\n  temperature=0.7     # temperature parameter\n)\n\nresponse = completion.choices[0].message.content\n\nprint(messages)\n\n[{'role': 'system', 'content': 'You are a reporter for The Economist covering environmental economics'}, {'role': 'user', 'content': 'First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use \\nper single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to \\nuse the most recent scientific estimates and cite your sources.'}]\n\n\n\nfor resp in completion.choices: \n    print(resp.message.content)\n    print('---')\n\nMy knowledge cutoff date is September 2021. \n\n1. \"Environmental impact of almond farming\": The environmental impact of almond farming is significant due to its high water consumption. It is estimated that it takes around 1.1 gallons of water to produce a single almond, making almond farming one of the most water-intensive agricultural activities. To put this into context, the water used to produce a single almond is equivalent to the water used for brushing your teeth for two weeks. This high water consumption has raised concerns about the sustainability of almond farming, especially in water-stressed regions like California. (Source: University of California, Davis)\n\n2. \"Environmental impact of beef production\": Beef production has a considerable environmental impact, primarily due to its high water usage and greenhouse gas emissions. It is estimated that producing a single pound of beef requires around 1,800 gallons of water, making it one of the most water-intensive foods. To put this in perspective, the water used to produce a single pound of beef is equivalent to the water used for brushing your teeth for over six months. Additionally, beef production is a significant contributor to deforestation and methane emissions, further exacerbating its environmental impact. (Source: Water Footprint Network)\n\n3. \"Environmental impact of plastic bottle manufacturing\": The environmental impact of plastic bottle manufacturing is substantial, particularly in terms of energy consumption and greenhouse gas emissions. It is estimated that producing a single plastic bottle requires around 1.5 gallons of water, mostly for the production of raw materials and the manufacturing process. To put this in context, the water used to produce a single plastic bottle is equivalent to the water used for brushing your teeth for three days. Additionally, the production and disposal of plastic bottles contribute to pollution and marine debris, posing a threat to ecosystems and wildlife. (Source: The Guardian)\n---\nMy knowledge cutoff is September 2021.\n\n1. \"Environmental impact of almond production per single query compared to other water intensive activities\"\nAlmond production is known to be water-intensive, with estimates suggesting that it takes about 1.1 gallons of water to produce a single almond. This high water usage has raised concerns about the environmental impact of almond farming, particularly in regions facing water scarcity. To put this into context, the water used to produce one almond is equivalent to the amount of water used for brushing your teeth for over two minutes. This comparison highlights the significant water footprint of almond production and the need for sustainable water management practices in the industry (UC Davis, 2021).\n\n2. \"Environmental impact of avocado production per single query compared to other water intensive activities\"\nAvocado production is another water-intensive agricultural activity, with estimates indicating that it takes around 74.1 gallons of water to produce a single pound of avocados. This high water usage has raised concerns about the environmental impact of avocado farming, especially in regions where water resources are limited. To put this into perspective, the water used to produce one pound of avocados is equivalent to the amount of water used for brushing your teeth for about 37 minutes. This comparison underscores the significant water footprint of avocado production and the importance of implementing water-efficient practices in the industry to mitigate environmental impacts (Water Footprint Network, 2021).\n---\nMy knowledge cutoff is September 2021.\n\n1. \"Environmental impact of almond farming\": Almond farming is a water-intensive activity, with estimates suggesting that it takes about 1.1 gallons of water to produce a single almond. This is a significant amount considering that California, a major almond-producing region, faces water scarcity issues. The environmental impact of almond farming includes the depletion of groundwater resources and potential harm to local ecosystems due to excessive water use. To put this into perspective, the water used to produce one almond is roughly equivalent to the water used for brushing your teeth 17 times (which typically uses about 0.063 gallons per minute for a recommended two-minute brush). Source: University of California, Davis.\n\n2. \"Environmental impact of beef production\": Beef production is a highly water-intensive process, with estimates suggesting that it takes approximately 1,800 gallons of water to produce one pound of beef. This is due to the water required for growing animal feed, providing drinking water for the cattle, and processing the meat. The environmental impact of beef production includes water pollution from animal waste and the greenhouse gas emissions associated with livestock farming. To put this into context, the water used to produce one pound of beef is equivalent to the water used for brushing your teeth for about 28,500 times. Source: Water Footprint Network.\n\n3. \"Environmental impact of cotton cultivation\": Cotton cultivation is another water-intensive activity, with estimates suggesting that it takes around 2,700 gallons of water to produce one cotton t-shirt. Water is primarily used for irrigating cotton fields, and the environmental impact includes the depletion of freshwater resources and potential contamination from agrochemicals used in cotton farming. To provide context, the water used to produce one cotton t-shirt is equivalent to the water used for brushing your teeth for approximately 42,800 times. Source: World Wildlife Fund.\n\nOverall, these examples highlight the significant water footprint of various agricultural activities and their potential environmental consequences when compared to everyday water usage for activities like brushing teeth.\n---\n\n\nWow! These didn’t really even understand the question\n\n\nPart 3: o3-mini\n\nmodel = \"o3-mini\"\nsystem_role = \"You are a reporter for The Economist covering environmental economics\"\ninitial_prompt = '''First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use \nper single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to \nuse the most recent scientific estimates and cite your sources.'''\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_role} ,\n    {\"role\": \"user\", \"content\": initial_prompt},\n    # {\"role\": \"assistant\", \"content\": \"\" },\n    # {\"role\": \"user\", \"content\": \"\" }\n]\n\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=model,        # the model to use \n  messages=messages,  # a list of dictionaries with the prompt\n  n=3,                # how many responses to generate\n)\n\nresponse = completion.choices[0].message.content\n\n\nfor resp in completion.choices: \n    print(resp.message.content)\n    print('---')\n\nMy knowledge cutoff is October 2023. Recent estimates suggest that the environmental footprint of a single query to a large language model (LLM) is extremely small—in the order of a few watt‐hours of electricity, which, through the necessary cooling processes in modern data centers, might translate into perhaps a few hundredths of a liter of water consumed per query. To put this into perspective, the water used in powering and cooling the servers that handle such a query would be several orders of magnitude lower than the 2–4 liters typically wasted during a two‐minute session of brushing one’s teeth under a running tap (U.S. Environmental Protection Agency, 2022). The rigorous energy and water management protocols now adopted by major cloud providers mean that each LLM query carries a lighter environmental toll than other daily water-intensive activities; indeed, while thousands of queries may collectively contribute to a measurable environmental demand, an individual query’s impact remains negligible relative to everyday water usage. (See also Strubell et al., 2019, for broader energy and policy considerations in machine learning.)\n---\nMy knowledge cutoff is 2023-10. \n\nRecent estimates indicate that serving a single query to a large language model (LLM) consumes on the order of 0.1–0.3 watt‐hours (Wh) of energy, though values vary with model size, hardware efficiency, and data center design (Strubell et al., 2019). In data centers that use water-based cooling systems, roughly 1–2 liters of water may be consumed per kilowatt‐hour generated (U.S. Department of Energy, 2020), which implies that the water footprint per LLM query is in the order of 0.0001–0.0006 liters—extremely small in absolute terms. To put this in perspective, brushing your teeth typically uses between 2 and 5 liters of water per session, especially if the tap runs continuously, meaning that the water used per LLM query is several orders of magnitude lower than that of a single dental hygiene routine. However, while the water and energy costs of an individual query are minute, the vast aggregate demand from billions of queries underscores the importance of improving data center efficiency and pursuing greener AI technologies. (Sources: Strubell et al., 2019, “Energy and Policy Considerations for Deep Learning in NLP”; U.S. Department of Energy, 2020, Data Center Water Usage Assessment.)\n---\nMy knowledge cutoff is 2023-10. Recent research shows that while large language model (LLM) queries do have an environmental impact, the water usage per query is very low compared to everyday activities. LLMs run on data centers that require electricity and cooling, with cooling systems in water-cooled facilities typically consuming anywhere from a few milliliters to a few tens of milliliters of water per kilowatt‐hour of processing, depending on the technology and local energy mix (Shehabi et al., 2016). For a single query that might use on the order of 10 Wh, the attributable water use can be roughly estimated in the range of 10–50 ml. In contrast, a standard two-minute session of brushing your teeth with the tap running can easily use 1–2 liters of water (U.S. EPA), meaning that even on a water-intensive day, the water footprint from an individual LLM query is orders of magnitude smaller. These comparisons underscore that while optimizing AI infrastructure for reduced energy and water use is important, the water use per query remains relatively minor when set against typical domestic water consumption practices. (Sources: Shehabi et al., 2016; U.S. Environmental Protection Agency)\n---\n\n\nInteresting how these cite primarily the EPA and papers from many years ago.\n\n\n\nSo what’s the correct answer?\nThere is none, and that’s part of why I thought this exercise was fun.\nOne study from Yale in February 2024 suggests that “a person who engages in a session of questions and answers with GPT-3 (roughly 10 to 50 responses) drives the consumption of a half-liter of fresh water”.\nSo if we do the math based on this one estimate, each query is somewhere between 0.05 and 0.01 liters of water. But this may vary a lot for other LLM models, too. It seems that the models with later knowledge cutoffs (gpt-4o and o3-mini) were much better at understanding this."
  },
  {
    "objectID": "posts/001_housing_data.html",
    "href": "posts/001_housing_data.html",
    "title": "Can ChatGPT help me open the correct PDF?",
    "section": "",
    "text": "Hi everyone,\nWelcome to my first post! Today, I’m looking at ChatGPT’s ability to do understand the structure of Census data. The data are organized into different PDFs as follows.\n\nPart 1: United States and Geographic Divisions\nPart 2: Akron, OH – Des Moines, IA\nPart 3: Detroit, MI – Memphis, TN\nPart 4: Miami, FL – Salt Lake City, UT\nPart 5: San Antonio, TX – Youngstown, OH\n\n\nThe task\nI was curious if ChatGPT would be able to tell me which section would contain data for Philadelphia.\n\n\n\nNot a great start\n\n\nInspired by the concept of prewarming or internal retrieval described in Prompt Engineering for Generative AI (Phoenix and Taylor 2024), I decided to ask ChatGPT if it could find a pattern in the file structures. Then, referencing our previous exchange where it discovered the pattern, I would ask it to try the task again.\n\n\n\nBetter!\n\n\nOk, time for the internal retrieval to shine.\n\n\n\nAlmost there…\n\n\n\nPros: ChatGPT was able to remember that it had previously found that the files were ordered alphabetically when I started the next prompt with “With that in mind”.\n\n\nCons:  ChatGPT is not correctly retrieving the order of the alphabet.\n\nAfter expressing some doubt in the alphabetization, ChatGPT was able to provide me with the correct answer.\n\nAnd just to be sure, I asked it about a different US city, and it was able to complete the task.\n\n\n\nSo, could this have been done all in one prompt?\nI closed out my current session of ChatGPT and tried to create one prompt that would make ChatGPT do some sort of internal retrieval.\nI ended up trying this:\n\nHi! I have a two part question. These are pdf names that have housing data for various US cities in 1950….\n\n\nQuestion 1: Why do you think Akron, OH comes before Des Moines, IA, and Des Moines, IA comes before Detroit, MI? Explain your reasoning. Question 2: Which pdf do you think Philadelphia, PA would be in? Explain your reasoning.\n\nChatGPT was able to correctly answer Question 1: saying “The cities are likely listed in alphabetical order (from A to Z), which is why Akron, OH appears before Des Moines, IA, and Des Moines, IA comes before Detroit, MI”.\nBut when it came to Question 2, there was more work still to be done.\n\nThen I thought maybe a three part question would help:\n\nQuestion 1: Why do you think Akron, OH comes before Des Moines, IA, and Des Moines, IA comes before Detroit, MI? Explain your reasoning. Question 2: Can you please print out the order of the alphabet? Question 3: Which pdf do you think Philadelphia, PA would be in? Explain your reasoning.\n\n\nSigh! I will have to try this again some other time once I’ve learned more about prompting strategies."
  }
]