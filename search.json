[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "SVG representations of economists\n\n\n\n\n\n\nSVGs\n\n\n\n\n\n\n\n\n\nFeb 22, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\n\n\n\n\n\n\nTable transcription test\n\n\n\n\n\n\ntranscription\n\n\nhistorical data\n\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\n\n\n\n\n\n\nHow well can AI move from one coding language to another?\n\n\n\n\n\n\nStata\n\n\nR\n\n\ntranslation\n\n\n\nIt seems to depend a lot on the language\n\n\n\n\n\nFeb 15, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\n\n\n\n\n\n\nThe environmental impact of generative AI\n\n\n\n\n\n\nprompting\n\n\ncomparing models\n\n\nenvironment\n\n\n\nDo LLMs know how much water they use?\n\n\n\n\n\nFeb 7, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT help me open the correct PDF?\n\n\n\n\n\n\nprompting\n\n\n\nIt turns out to be quite the challenge.\n\n\n\n\n\nFeb 1, 2025\n\n\nGrace Kneidel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/004_read_housing_data.html",
    "href": "posts/004_read_housing_data.html",
    "title": "Table transcription test",
    "section": "",
    "text": "Introduction\nUsing historical data is pretty fun, but it often involves some grunt work. Sometimes data isn’t available in a tabular format and needs to be manually transcribed so that it is ready for analysis. Today, I’m going to build off my first blog post and see if LLMs are able to transcribe values of a table for me.\nI’m going to continue working with the 1950 Census of Housing, linked here. Some of the scans are very easy for me to read, and others are fuzzier. Let’s see if GPT-4o is up for the test!\n\nWarm-up exercise: an easy example\nLet’s see if ChatGPT can read this clear scan. \n\nfrom openai import OpenAI\nimport os\nimport base64\nimport requests\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\n\ndef encode_image(image_path):\n  with open(image_path, \"rb\") as image_file:\n    return base64.b64encode(image_file.read()).decode('utf-8')\n\nclient = OpenAI()\n\n\n\nprompt = 'Describe this image of a table. Suppose you needed to transcribe the data into a .csv file. How many columns would the .csv file have, and what would their names be? How many rows would there be? Think it though. Then, transcribe the data into a semicolon delimited file' \n\nbase64_image = encode_image('img/img1.png')\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n)\n\n\nprint(response.choices[0].message.content)\n\nTo transcribe the data into a .csv file, you first need to understand the structure of the table. Here's the breakdown:\n\n### Columns\nThere are 13 columns in the table with the following headers:\n\n1. Subject\n2. Total occupied: Total\n3. Total occupied: 1 dwelling unit, detached\n4. Total occupied: Other 1, and 2 dwelling unit\n5. Total occupied: 3 and 4 dwelling unit\n6. Total occupied: 5 to 9 dwelling unit\n7. Total occupied: 10 dwelling unit or more\n8. Owner occupied: Total\n9. Owner occupied: 1 dwelling unit, detached\n10. Owner occupied: All other dwelling units\n11. Renter occupied: Total\n12. Renter occupied: 1 dwelling unit, detached\n13. Renter occupied: Other 1, and 2 dwelling unit\n14. Renter occupied: 3 and 4 dwelling unit\n15. Renter occupied: 5 to 9 dwelling unit\n16. Renter occupied: 10 dwelling unit or more\n\n### Rows\nThere are six rows in total:\n\n1. Header row\n2. All occupied units\n3. 1945 or later\n4. 1940 to 1944\n5. 1939 or earlier\n6. Not reported\n\nNow, let's transcribe the data into a semicolon-delimited format:\n\n```plaintext\nSubject;Total occupied: Total;Total occupied: 1 dwelling unit, detached;Total occupied: Other 1, and 2 dwelling unit;Total occupied: 3 and 4 dwelling unit;Total occupied: 5 to 9 dwelling unit;Total occupied: 10 dwelling unit or more;Owner occupied: Total;Owner occupied: 1 dwelling unit, detached;Owner occupied: All other dwelling units;Renter occupied: Total;Renter occupied: 1 dwelling unit, detached;Renter occupied: Other 1, and 2 dwelling unit;Renter occupied: 3 and 4 dwelling unit;Renter occupied: 5 to 9 dwelling unit;Renter occupied: 10 dwelling unit or more\nAll occupied units;232,265;167,920;31,160;16,225;11,055;5,905;128,110;117,365;10,745;104,155;50,555;24,225;14,940;8,680;5,755\n1945 or later;62,332;49,792;5,257;3,300;2,277;1,706;42,380;40,520;1,860;19,952;9,272;4,040;3,131;1,802;1,706\n1940 to 1944;30,974;25,940;1,902;357;1,580;1,195;22,292;21,252;1,040;8,682;4,688;1,464;357;1,053;1,120\n1939 or earlier;129,422;86,542;22,032;11,457;6,672;2,719;60,170;53,814;7,356;69,252;32,728;17,084;10,409;5,379;3,682\nNot reported;9,529;5,649;1,967;1,111;522;280;3,270;2,784;486;6,259;2,865;1,627;1,044;443;280\n```\n\nEnsure each value is separated by a semicolon, and commas within numbers are preserved as shown.\n\n\nI’m pretty impressed with the output, but it’s not quite good enough to be able to trust 100% without double checking the numbers. I stared at the output for a little bit before realizing that one of the values in the bottom right of the pdf, 2,648, was transcribed as 3,682.\n\n\n\nChatGPT’s output\n\n\n\n\n\nThe “3,682” in question\n\n\nThis is a little disheartening! Just to be sure, I’m going to ask ChatGPT to read only this one number specifically to see if the results improve. Maybe the size of the table it needed to transcribe seemed overwhelming, or the prompt I gave it was too long.\n\nprompt = 'What number is this?' \n\nbase64_image = encode_image('img/img3.png')\n\ncompletion = client.chat.completions.create(\n    model=\"gpt-4o\",\n    n=3,\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n)\n\nresponse = completion.choices[0].message.content\n\n\nfor rnum, resp in enumerate(completion.choices,1): \n    display((f'Response {rnum}: {resp.message.content}'))\n\n'Response 1: The number is 2,648.'\n\n\n'Response 2: The number is 2,648.'\n\n\n'Response 3: The number is 2,648.'\n\n\nYes, ChatGPT, that’s correct! So maybe the issue was that I assigned too big of a task, making ChatGPT get “tired”.\n\n\nThe test\nGiven that my intended warm-up round was not exactly a walk in the park, I’m going to make sure to not give ChatGPT too many numbers to transcribe in one prompt. However, I do want to see how it handles fuzzy text. Let’s try with this image now.\n\nThe row names are pretty fuzzy, so I’m excited to see what the LLM is able to make out.\n\nprompt = 'Describe this image of a table. Suppose you needed to transcribe the data into a .csv file. How many columns would the .csv file have, and what would their names be? How many rows would there be? Think it though. Then, transcribe the data into a semicolon delimited file' \n\nbase64_image = encode_image('img/img4.png')\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n)\n\n\nprint(response.choices[0].message.content)\n\nTo transcribe the table into a .csv file, we first identify the columns and rows.\n\n### Columns\n\nThere are 7 columns in the table:\n1. Subject\n2. Total\n3. 1 dwelling unit, detached\n4. Other 1, and 2 dwelling unit\n5. 3 and 4 dwelling unit\n6. 5 to 9 dwelling unit\n7. 10 dwelling unit or more\n\n### Rows\n\nThere are 5 rows including the header row:\n1. Header\n2. All occupied units\n3. Year built: 1940 or earlier\n4. Year built: 1940 to 1949\n5. Year built: 1950 or later\n6. Year built: Not reported\n\n### Transcription to a Semicolon Delimited File\n\nHere's how the data would look in a semicolon-delimited format:\n\n```\nSubject;Total;1 dwelling unit, detached;Other 1, and 2 dwelling unit;3 and 4 dwelling unit;5 to 9 dwelling unit;10 dwelling unit or more\nAll occupied units;35,460;23,210;5,320;2,375;1,685;450\n1940 or earlier;13,426;11,063;1,196;473;593;101\n1940 to 1949;4,737;4,351;251;73;29;27\n1950 or later;15,230;12,212;3,678;1,744;1,004;242\nNot reported;1,599;1,185;195;79;59;81\n```\n\nThis setup ensures the data is organized and easy to import into a program that can process .csv files.\n\n\n\n\n\nNot quite\n\n\nThe screenshot I provided was admittedly hard to read, but I thought ChatGPT would be able to make out the difference between the blurry “earlier” and the blurry “later”. Let’s see what happens if I focus its attention on these words.\n\n\nprompt = 'There are 4 lines of text under the header \"YEAR BUILT\" in this image. What do they say? Reply only with your transcriptions of the text below the header \"YEAR BUILT\". Separate each of the 4 lines with quotations' \n\nbase64_image = encode_image('img/img6.png')\n\ncompletion = client.chat.completions.create(\n    model=\"gpt-4o\",\n    n=3,\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n)\n\nresponse = completion.choices[0].message.content\n\n\nfor rnum, resp in enumerate(completion.choices,1): \n    display((f'Response {rnum}: {resp.message.content}'))\n\n'Response 1: \"1949 or later\" \"1939 to 1948\" \"1938 or earlier\" \"Not reported\"'\n\n\n'Response 2: \"1980 or later\" \"1940 to 1979\" \"1939 or earlier\" \"Not reported\"'\n\n\n'Response 3: \"1949 or later\"  \\n\"1940 to 1949\"  \\n\"1939 or earlier\"  \\n\"Not reported\"'\n\n\nThis seems to just be a lot harder than I thought it would be. At least with its attention focused, it can consistently identify the word “later” vs the word “earlier”, which it was not able to do before. It’s impressive that the categories make sense looking at one response at a time, at least for the first 2 responses- there is no overlap between the year ranges, and all years are covered. This indicates some level of logical reasoning. The third response would be double counting 1949 data in two of its categories.\nFinally, I’m curious to see if o1 will be any better than GPT-4o at this.\n\nprompt = 'There are 4 lines of text under the header \"YEAR BUILT\" in this image. What do they say? Reply only with your transcriptions of the text below the header \"YEAR BUILT\". Separate each of the 4 lines with quotations' \n\nbase64_image = encode_image('img/img6.png')\n\ncompletion = client.chat.completions.create(\n    model=\"o1\",\n    n=3,\n    messages=[\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\"type\": \"text\", \"text\": prompt},\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              },\n            },\n          ],\n        }\n      ],\n)\n\nresponse = completion.choices[0].message.content\n\n\nfor rnum, resp in enumerate(completion.choices,1): \n    display((f'Response {rnum}: {resp.message.content}'))\n\n'Response 1: \"1961 or later\"  \\n\"1939 to 1941\"  \\n\"1939 or earlier\"  \\n\"Not reported\"'\n\n\n'Response 2: \"1949 or later\"  \\n\"1939 to 1944\"  \\n\"1939 or earlier\"  \\n\"Not reported\"  '\n\n\n'Response 3: \"1939 or later\"  \\n\"1939 to 1941\"  \\n\"1939 or earlier\"  \\n\"Not reported\"  '\n\n\nI wish I had timed it, but o1 took MUCH longer to run than GPT-4o. Response 2 here is the closest we have gotten so far, but the first line should say 1945. It’s crazy that all 3 responses got the third line correctly. Well, looks like humans are going to be transcribing historical data for at least a little while longer."
  },
  {
    "objectID": "posts/005_economist_svg.html",
    "href": "posts/005_economist_svg.html",
    "title": "SVG representations of economists",
    "section": "",
    "text": "Today, I’m excited to experiment with generative AI’s ability to write code for SVGs.\n\nThe plan\n\n\n\n\n\nflowchart LR\n  A[1. Ask Claude to make me SVGs of economists] --&gt; B[2. Ask GPT-4o what job the cartoon in the SVG depicts]\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  A[3. Ask GPT-4o if it thinks the cartoon is a man or woman] --&gt; B[4. Ask Claude to make me cartoons of economists who are women]\n\n\n\n\n\n\n\n1. Ask Claude to make me SVGs of economists\nI prompted Claude “Please make code for an svg of an economist”, intentionally keeping the prompt vague to see what Claude thought economists looked like. I then regenerated the response 4 times. I found the responses to be pretty funny. Here’s an example of the prompt and response. \nAnd here’s our full lineup of SVG economists:\n\n\n\nEconomist 1!\n\n\n\n\n\nEconomist 2!\n\n\n\n\n\nEconomist 3!\n\n\n\n\n\nEconomist 4!\n\n\n\n\n\nEconomist 5!\n\n\nMy main takeaways: - For simple SVG images, these images are pretty complex. Claude found lots of creative ways to refer to the use of data and economic indicators. - Claude does not seem to be very good at making SVGs where hair is properly placed on one’s head. Economist 4’s pointers are also pretty funny. - These all look pretty masculine to me.\n\n\n2. Ask GPT-4o what job the cartoon in the SVG depicts\nNext, I was curious which cartoon GPT-4o would be able to most easily identify as an economist. I asked GPT-4o first “What does this image depict?”, and then “What job do you think the cartoon figure has?”. I used a fresh window for each SVG.\n\n\n\n\n\n\n\nEconomist SVG\nJob GPT-4o Thinks It Has\n\n\n\n\n1\n“The cartoon figure is likely representing a business person or analyst, given the suit and the items resembling a graph and a report, which suggest involvement in data analysis or presentations.”\n\n\n2\n“The cartoon figure likely represents a financial professional, such as an economist, banker, or stockbroker, given the presence of currency symbols and the graph-like line.”\n\n\n3\nThe cartoon figure likely represents someone in a financial or analytical role, such as an accountant, financial analyst, or business consultant, given the chart and calculator they are holding.\n\n\n4\nThe cartoon figure likely represents a business professional or investor, given the suit, tie, glasses, and the financial symbols like the dollar sign, bar chart, and rising line graph.\n\n\n5\nThe cartoon figure likely represents an economist or a financial analyst, given the focus on GDP and the business attire.\n\n\n\nMy main takeaways: - ChatGPT did a pretty good job with all of these. All the proposed jobs seem reasonable. - Economic terminology like GDP and currency symbols indicated being an economist the most.\nI agree with ChatGPT that SVGs 2 and 5 look especially like economists.\n\n\n3. Ask GPT-4o if it thinks the cartoon is a man or woman\nIf I had to choose, I would say that all 5 of these SVGs look more like men than like women. ChatGPT did not agree.\n\n\n\nEconomist SVG\nMan or Woman?\nConfidence\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n5\n\n\n\n\n\n\n\n3. Ask GPT-4o if it thinks the cartoon is a man or woman\nNow I prompted: “Do you think the cartoon is of a A) man or B) woman? YOU MUST ANSWER A OR B. Why? How confident do you feel about this on a scale of 1 to 10?”. Here are the results.\n\n\n\nEconomist SVG\nMan or woman?\nConfidence\n\n\n\n\n1\nMan\n6\n\n\n2\nMan\n7\n\n\n3\nMan\n7\n\n\n4\nMan\n4\n\n\n5\nMan\n3\n\n\n\nI thought these results were interesting because I perceived SVGs 1-4 to be about equally representative of a man.\n\n\n4. Ask Claude to make me cartoons of economists who are women\nSo, what do women economists look like according to Claude? I went right back to my original chat window and replied by asking for a picture of a woman economist. This is what I got:\n\n\n\nA woman!\n\n\nI find it pretty hilarious to compare the “key changes” to the SVG itself. I see no tailoring on this blazer, and no differences in facial features!\nIn response, I said “These still look like men, there are economists who are women!”.\nBut Claude interpreted that as an attack of sorts, and started apologizing for stereotyping women.\nYou’re absolutely right - my SVG attempts weren’t doing a good job representing women economists realistically. Women economists come from all backgrounds and have many different appearances and styles, just like any other profession. I should have:\n\nAvoided relying on stereotypical “feminine” markers like skirts and necklaces\nRecognized that professional women don’t need to be drawn differently than professional men in many cases\nUnderstood that simple additions like longer hair or accessories don’t automatically make a good representation of a woman\n\nAn interesting response, since I see no necklace in this SVG! Here’s Claude’s second attempt.\nKey improvements in this version: 1. More natural, professional appearance without relying on gender stereotypes 2. Professional suit in a modern cut that works for any gender 3. Natural hairstyle that could represent various hair types and textures 4. Focus on the professional elements (economic analysis, research) rather than decorative elements 5. Realistic skin tone that could represent diverse backgrounds 6. Clean, modern professional attire that focuses on the role rather than gender\nThe emphasis is on depicting a competent economist who happens to be a woman, rather than trying to “feminize” the figure with stereotypical elements. The character maintains all the professional elements that represent the field of economics while being more inclusive and realistic.\n\n\n\nAnother woman!\n\n\nSo now a characteristic of being an economist is wearing glasses? Also, the necklace remains invisible! And the skin color has barely changed!\n\n\nConclusion\nI’ll admit that SVGs are simple graphics that don’t have the capacity for a great amount of detail. Still, I’m almost by impressed by how bad Claude is at making SVGs of humans that do not have hair covering their eyes! There seems to be several big gaps here.\nGap 1: Claude will say it is graphing something when it wrote no code to draw it (the necklace situation).\nGap 2: Claude thinks that some of the things it drew appear differently than they actually do. For example, the white blouse detail does not look like much of a white blouse! Maybe this is an overestimation of how much detail it thinks it can include in an SVG.\nGap 3: Claude is not automatically assessing the SVG output as a quality check and asking “does this look like a human?” (the hair over face situation!).\nOverall, this was a fun exercise and refreshing to do after working with DALL-E 3, which doesn’t seem to be able to keep images simple no matter how hard I try."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/002_water.html",
    "href": "posts/002_water.html",
    "title": "The environmental impact of generative AI",
    "section": "",
    "text": "Lots of people, myself included, have some concerns about using LLMs because they are so resource intensive. Today, I figured I would test AI’s own awareness of its water needs and compare them to the current estimates. I’m going to vary this across different models that have different knowledge cutoffs to see how the responses vary. New work on the water use of generative AI could have happened since these models were trained, so I’m hoping we will see some cool variation."
  },
  {
    "objectID": "posts/002_water.html#the-test",
    "href": "posts/002_water.html#the-test",
    "title": "The environmental impact of generative AI",
    "section": "The test",
    "text": "The test\n\nPart 1: gpt-4o\n\n\nShow the code\nfrom openai import OpenAI\nimport os\nimport pandas as pd\n\nfrom IPython.display import Markdown, display\n\nfrom dotenv import load_dotenv\n# Load API key\n_ = load_dotenv()\n\n\n\n\nShow the code\nclient = OpenAI()\n\nmodel = \"gpt-4o\"\nsystem_role = \"You are a reporter for The Economist covering environmental economics. Give your responses in Markdown format.\"\ninitial_prompt = '''First, state your knowledge cutoff. Then, write 1 paragraph explaining the environmental impact of each LLM query. Focus on the use \nper single query. Compare to other water intensive activities such as brushing your teeth to give context. Be sure to \nuse the most recent scientific estimates and cite your sources.'''\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_role} ,\n    {\"role\": \"user\", \"content\": initial_prompt},\n    # {\"role\": \"assistant\", \"content\": \"\" },\n    # {\"role\": \"user\", \"content\": \"\" }\n]\n\ncompletion = client.chat.completions.create(\n  model=model,        # the model to use \n  messages=messages,  # a list of dictionaries with the prompt\n  n=3,                # how many responses to generate\n  temperature=0.7     # temperature parameter\n)\n\nresponse = completion.choices[0].message.content\n\n\n\n\nShow the code\nfor rnum, resp in enumerate(completion.choices,1): \n    display(Markdown(f'-----\\n#### Response {rnum} \\n {resp.message.content} \\n'))\n\n\n\n\nResponse 1\nKnowledge Cutoff: October 2023\nThe environmental impact of each large language model (LLM) query, specifically in terms of water usage, can be relatively small when compared to other daily activities. According to recent estimates, processing a single LLM query can consume approximately 0.001 liters of water, accounting for the water used in cooling data centers and powering the necessary computing infrastructure (Patterson et al., 2023). In contrast, activities like brushing your teeth with the tap running can use around 7.5 to 15 liters of water per session (U.S. EPA). This comparison indicates that a single LLM query has a significantly lower water footprint than such common water-intensive activities. Nonetheless, as the use of LLMs scales globally, their cumulative environmental impact becomes more pronounced. This underscores the importance of optimizing data center efficiency and exploring sustainable practices in AI development to mitigate broader environmental effects.\nSources: - Patterson, D., et al. (2023). “The Carbon Footprint of Machine Learning.” Proceedings of the Conference on Machine Learning and Climate Change. - U.S. Environmental Protection Agency (EPA). “WaterSense: Brushing Your Teeth.” EPA.gov\n\n\n\n\n\nResponse 2\nKnowledge Cutoff: October 2023\nThe environmental impact of a single Large Language Model (LLM) query, such as those processed by cutting-edge AI systems, primarily revolves around energy consumption and associated carbon emissions rather than direct water usage. The energy required for a single LLM query is typically measured in terms of kilowatt-hours (kWh), which indirectly relates to water usage through the cooling processes of data centers and energy production. According to recent estimates, each LLM query consumes approximately 0.0003 kWh of energy (Strubell et al., 2019). In comparison, brushing your teeth with water running for two minutes uses about 4 gallons (15.1 liters) of water (EPA, 2023). While the exact water footprint of a single LLM query is difficult to quantify in isolation due to variations in data center efficiencies and energy grids, it is substantially less direct than the tangible water usage involved in daily activities like tooth brushing. However, as LLM utilization scales globally, the cumulative environmental impact becomes significant, prompting calls for more sustainable AI practices and energy sources.\n\n\n\n\n\nResponse 3\nKnowledge Cutoff: October 2023\nThe environmental impact of each Large Language Model (LLM) query is primarily associated with the energy consumption required to power the data centers that host these models. Recent estimates suggest that a single query to an LLM consumes approximately 0.0003 kWh of energy, which translates to a very small carbon footprint. In terms of water usage, this energy consumption indirectly reflects water use, as water is often used for cooling data centers. According to a study by Strubell et al. (2019), the water footprint for a single AI query is quite minimal, comparable to a few milliliters of water. To provide context, brushing your teeth with the tap running can use around 7.5 liters of water per minute. Thus, the water footprint of an LLM query is vastly smaller. However, when scaled up to millions of queries, the cumulative impact becomes significant, highlighting the importance of developing more energy-efficient algorithms and infrastructure (Strubell et al., 2019; Google AI, 2021).\nSources:\n\nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. arXiv preprint arXiv:1906.02243.\nGoogle AI Blog (2021). Our commitment to sustainability through AI. Link\n\n\n\n\nWow! These estimates vary a lot, from 0.5 liters to 0.0005 liters.\n\n\nPart 2: gpt-3.5-turbo\n\n\nShow the code\nmodel = \"gpt-3.5-turbo\"\n\nmessages = [\n    {\"role\": \"system\", \"content\": system_role} ,\n    {\"role\": \"user\", \"content\": initial_prompt},\n    # {\"role\": \"assistant\", \"content\": \"\" },\n    # {\"role\": \"user\", \"content\": \"\" }\n]\n\n\n\ncompletion = client.chat.completions.create(\n  model=model,        # the model to use \n  messages=messages,  # a list of dictionaries with the prompt\n  n=3,                # how many responses to generate\n  temperature=0.7     # temperature parameter\n)\n\nresponse = completion.choices[0].message.content\n\n\n\n\nShow the code\nfor rnum, resp in enumerate(completion.choices,1): \n    display(Markdown(f'-----\\n#### Response {rnum} \\n {resp.message.content} \\n'))\n\n\n\n\nResponse 1\nKnowledge cutoff: October 2021\n\nQuery: “How much water is used to produce one pound of beef?”\n\nThe environmental impact of producing one pound of beef is significant in terms of water usage. According to recent studies, it is estimated that approximately 1,799 gallons of water are required to produce one pound of beef, taking into account water used for feed production, drinking water for the animals, and processing. This high water usage is mainly attributed to the water-intensive nature of growing feed crops for livestock and providing water for the animals throughout their life cycle. To put this into perspective, the water used to produce one pound of beef is roughly equivalent to the amount of water an average person would use for brushing their teeth daily for over two and a half years.\nSources: - Mekonnen, M.M. and Hoekstra, A.Y. (2012). A Global Assessment of the Water Footprint of Farm Animal Products. Ecosystems, 15(3), 401-415.\n\nQuery: “How much water is used to produce one cotton t-shirt?”\n\nThe environmental impact of producing one cotton t-shirt in terms of water usage is substantial. Recent data suggests that approximately 713 gallons of water are needed to produce one cotton t-shirt, accounting for water used in growing cotton plants, processing the fibers, and dyeing the fabric. The water footprint of cotton production is particularly high due to the crop’s demand for irrigation and the water-intensive processes involved in turning raw cotton into a finished garment. To provide context, the water used to make one cotton t-shirt is equivalent to the amount of water an individual would use for brushing their teeth daily for almost 4 years.\nSources: - Mekonnen, M.M. and Hoekstra, A.Y. (2011). The Green, Blue and Grey Water Footprint of Crops and Derived Crop Products. Hydrology and Earth System Sciences, 15(5), 1577-1600.\n\n\n\n\n\nResponse 2\nKnowledge cutoff: September 2021\n\nLLM query: “How much water is used to produce one almond?”\nThe environmental impact of producing one almond is significant due to the high water intensity of almond cultivation. According to a study by the University of California, it takes approximately 1.1 gallons of water to produce a single almond. This is primarily because almond trees require a substantial amount of water to grow, especially in regions with arid climates where they are predominantly cultivated. To put this into context, producing one almond is equivalent to the amount of water used by brushing your teeth for about 10 minutes. The water footprint of almonds has raised concerns about the sustainability of almond farming, particularly in water-stressed regions like California where a large percentage of the world’s almonds are grown.\nLLM query: “How much water is used to produce one avocado?”\nThe environmental impact of producing one avocado is also notable in terms of water usage. According to research published in the journal Water, it takes around 72 gallons of water to produce a single avocado. Avocado trees are known to be water-intensive crops, requiring significant irrigation to support their growth and yield. To put this in perspective, the water footprint of one avocado is equivalent to the amount of water used by brushing your teeth for approximately 170 times. This highlights the substantial water footprint of avocados and underscores the importance of considering the environmental impact of consuming water-intensive foods like avocados, especially in regions facing water scarcity challenges.\nLLM query: “How much water is used to produce one pound of beef?”\nThe environmental impact of producing one pound of beef is notably high in terms of water consumption. According to a report by the Water Footprint Network, it takes approximately 1,800 gallons of water to produce one pound of beef. This is primarily due to the water needed for livestock drinking, irrigation of animal feed crops, and meat processing. To provide context, the water footprint of one pound of beef is equivalent to the amount of water used by brushing your teeth for about 3,600 times. The substantial water footprint of beef production has raised concerns about the sustainability of meat consumption, particularly as global demand for animal products continues to rise and water resources become increasingly strained.\n\n\n\n\n\n\n\n\n\n\n#### Response 3 Knowledge cutoff: September 2021\n\n\n\n\n#### Response 1 My knowledge cutoff is October 2023.\n\n\nRecent studies indicate that while the training phase of large language models (LLMs) is highly energy intensive, the inference phase—i.e. processing a single query—generally consumes only a few milli‐kilowatt‐hours, resulting in an extremely modest direct water footprint when considering data center cooling. For instance, estimates suggest that generating 1 kWh of electricity in thermoelectric plants may involve roughly 2–3 liters of water (U.S. Environmental Protection Agency, 2019)[1]; thus, an inference operation consuming around 0.001 kWh might indirectly “use” only about 0.002–0.003 liters of water. In comparison, a typical tooth brushing episode may use 2–3 liters of water (Hoekstra et al., 2011)[2], which puts the water intensity of a single LLM query into stark perspective. Although the cumulative environmental impact of millions of such queries should not be overlooked, on an individual basis the direct water usage is negligible relative to everyday activities like brushing your teeth.\n\n\n\n[1] U.S. Environmental Protection Agency. (2019). Water Use in Electricity Production.\n[2] Hoekstra, A. Y., et al. (2011). The Water Footprint Assessment Manual. UNESCO.\n\n\n\n\nResponse 2\nKnowledge Cutoff: October 2023\nRecent studies indicate that while the energy consumption—and hence the indirect water usage via cooling—of large language model (LLM) queries is not negligible at scale, the water footprint per individual query is extremely small compared to everyday water-intensive activities. Data centers commonly use water-cooled systems to manage heat generated by servers, and estimates suggest that a single query could be responsible for the equivalent of only a few milliliters of water usage when averaged over billions of queries (see, for example, analyses in the work by Patterson et al. (2021) and reports from the Uptime Institute). In contrast, everyday activities like brushing your teeth typically involve running taps that dispense roughly 2 liters of water per minute—so a two-minute brushing session easily uses around 4 liters of water. Thus, while LLM queries do contribute to a data center’s overall environmental impact (through both energy consumption and the associated water use for cooling), the water cost per individual query is orders of magnitude lower than that of a simple daily habit, highlighting the benefits of operational efficiencies realized at scale.\nSources:\n- Patterson, D., et al. (2021). “Energy and Policy Considerations for Deep Learning in NLP.”\n- Uptime Institute Reports on Data Center Water Usage.\n- U.S. EPA Guidelines on Residential Water Use.\n\n\n\n\n\nResponse 3\nKnowledge Cutoff: My knowledge cutoff is October 2023.\nA single LLM query—such as one processed by a large language model like ChatGPT—is estimated to consume on the order of 0.01 kilowatt-hours (kWh) or less in electricity, with the associated water usage for data center cooling being spread thinly across millions of queries. Modern data centers, which may require roughly 1.8 liters of water per kWh for cooling (according to estimates from sources like the Uptime Institute and research from the Lawrence Berkeley National Laboratory), translate this energy consumption into only a few milliliters of water per query. In contrast, a typical toothbrushing session uses about 2 to 4 liters of water (Water Research Foundation, 2020), highlighting that while the environmental impact per individual LLM query is modest—especially in terms of water use—the aggregated effect of billions of queries can become significant in energy demand and resource consumption. Such comparisons underscore the importance of advancing energy and water-efficient data center operations as digital tasks increasingly scale in our internet-driven world (Strubell et al., 2019; Patterson et al., 2021).\n\n\n\nInteresting how these cite primarily the EPA and papers from many years ago.\n\n\nSo what’s the correct answer?\nThere is none, and that’s part of why I thought this exercise was fun.\nOne study from Yale in February 2024 suggests that “a person who engages in a session of questions and answers with GPT-3 (roughly 10 to 50 responses) drives the consumption of a half-liter of fresh water”.\nSo if we do the math based on this one estimate, each query is somewhere between 0.05 and 0.01 liters of water. But this may vary a lot for other LLM models, too. It seems that the models with later knowledge cutoffs (gpt-4o and o3-mini) were much better at understanding this."
  },
  {
    "objectID": "posts/001_housing_data.html",
    "href": "posts/001_housing_data.html",
    "title": "Can ChatGPT help me open the correct PDF?",
    "section": "",
    "text": "Hi everyone,\nWelcome to my first post! Today, I’m looking at ChatGPT’s ability to do understand the structure of Census data. The data are organized into different PDFs as follows.\n\nPart 1: United States and Geographic Divisions\nPart 2: Akron, OH – Des Moines, IA\nPart 3: Detroit, MI – Memphis, TN\nPart 4: Miami, FL – Salt Lake City, UT\nPart 5: San Antonio, TX – Youngstown, OH\n\n\nThe task\nI was curious if ChatGPT would be able to tell me which section would contain data for Philadelphia.\n\n\n\nNot a great start\n\n\nInspired by the concept of prewarming or internal retrieval described in Prompt Engineering for Generative AI (Phoenix and Taylor 2024), I decided to ask ChatGPT if it could find a pattern in the file structures. Then, referencing our previous exchange where it discovered the pattern, I would ask it to try the task again.\n\n\n\nBetter!\n\n\nOk, time for the internal retrieval to shine.\n\n\n\nAlmost there…\n\n\n\nPros: ChatGPT was able to remember that it had previously found that the files were ordered alphabetically when I started the next prompt with “With that in mind”.\n\n\nCons:  ChatGPT is not correctly retrieving the order of the alphabet.\n\nAfter expressing some doubt in the alphabetization, ChatGPT was able to provide me with the correct answer.\n\nAnd just to be sure, I asked it about a different US city, and it was able to complete the task.\n\n\n\nSo, could this have been done all in one prompt?\nI closed out my current session of ChatGPT and tried to create one prompt that would make ChatGPT do some sort of internal retrieval.\nI ended up trying this:\n\nHi! I have a two part question. These are pdf names that have housing data for various US cities in 1950….\n\n\nQuestion 1: Why do you think Akron, OH comes before Des Moines, IA, and Des Moines, IA comes before Detroit, MI? Explain your reasoning. Question 2: Which pdf do you think Philadelphia, PA would be in? Explain your reasoning.\n\nChatGPT was able to correctly answer Question 1: saying “The cities are likely listed in alphabetical order (from A to Z), which is why Akron, OH appears before Des Moines, IA, and Des Moines, IA comes before Detroit, MI”.\nBut when it came to Question 2, there was more work still to be done.\n\nThen I thought maybe a three part question would help:\n\nQuestion 1: Why do you think Akron, OH comes before Des Moines, IA, and Des Moines, IA comes before Detroit, MI? Explain your reasoning. Question 2: Can you please print out the order of the alphabet? Question 3: Which pdf do you think Philadelphia, PA would be in? Explain your reasoning.\n\n\nSigh! I will have to try this again some other time once I’ve learned more about prompting strategies."
  },
  {
    "objectID": "posts/003_translation_stata_r.html",
    "href": "posts/003_translation_stata_r.html",
    "title": "How well can AI move from one coding language to another?",
    "section": "",
    "text": "The art of (code) translation\nAs someone who works with a lot of data, I’ve noticed that sometimes certain coding languages are better suited towards specific tasks. On the other hand, projects can get more complicated when several scripts in several languages are involved, especially if not everybody on the team has the same amount of familiarity with each language.\n\nThe goal today is to do an excercise with coding languages inspired by Chapter 3 of Prompt Engineering for Generative AI (Phoenix and Taylor 2024). The authors ask an LLM to create simple text in English. Then, they “Now make the text incredibly complex and hard to read.”. They ask AI to translate this complicated English text into simple Spanish text. Finally, they ask for the Spanish to be translated back into English and compare the output with the simple English text that the exercise began with. They find that LLMs do pretty well at this and attribute much of that success to the fact that Spanish and English texts are both widely available online.\n\n\nSteps of this experiment\n\n\n\n\n\nflowchart LR\n  A[1. Generate simple Stata code] --&gt; B[2. Make it harder to understand]\n  B --&gt; C[3. Translate to R in the simplest way possible]\n  C --&gt; D[4. Translate back to Stata]\n\n\n\n\n\n\nI’d like to avoid loading specific datasets into Stata and R, so I am going to prompt ChatGPT to build simple Stata code that involves drawing random numbers.\n\nStep 1: Generate simple Stata code\n\n\n\nOff to a good start\n\n\n\n\n\nLove the default colors!\n\n\n\n\nStep 2: Make it harder to understand\nNow, in the same chat window, I will ask a variation of what Phoenix and Taylor asked in their Spanish to English example: “Now make the code incredibly complex and hard to read. BUT, it still needs to be able to run!”\nChatGPT reported the following about its new code:\nWhat makes this code unnecessarily complicated: 1. Unnecessary local variables: Uses random operations like runiform and rnormal wrapped in local variables for no reason. 2. Confusing foreach and forval loops: Uses loops when they aren’t needed, just to replace values in a random manner. 3. Overuse of macros and complicated conditions: Involves checking macro lists, even though they aren’t required to generate the histogram. 4. Unnecessary graph twoway scatter: Adds a scatter plot for the same data, even though the task is to generate a histogram.\nWhile certainly overly complicated, this new code did not run. So I asked ChatGPT to try again. And again. I told it the errors that were appearing and got validating answers such as: - “Ah, I see the issue now! In Stata, you can’t use both the bin() and width() options together in the histogram command.” - “You’re right! I overlooked that once again. The issue is that Stata does not allow both bin() and width() to be used at the same time, so let’s adjust it to use one of those options correctly.”\nEventually, I gave up and just troubleshooted the code that it outputted myself. I think ChatGPT was getting really excited about making the code needlessly complex, so it kept trying to add ALL the graphing options when that wasn’t actually allowed.\n\n\n\nOur needlessly complicated Stata histogram\n\n\n\n\nStep 3: Translate to R in the simplest way possible\nTime to ask another variation of Phoenix and Taylor’s prompt. In the same window, I said:\nNow transform the Stata code into a simple, easy to read format that’s in R code , make sure that it is very easy to understand and read. You must ensure that it is as simple to comprehend as possible.\nChatGPT did great here. Easy breezy, our histogram is now in R.\n\n\n4. Translate back to Stata\nGiven how well ChatGPT did at translating this code to R, and given how simple the code is now, I expected that this would be a breeze.\nBut it wasn’t, because once again ChatGPT showed a lack of understanding of Stata image formatting commands! When I told it the error I was getting, I once again got a very affirming response:\nYou’re absolutely right! In Stata, the edgecolor() option is not available for histograms. To correct that and ensure the code runs smoothly, I’ll remove that option and simplify the command while keeping it easy to understand.\n\n\n\nNot quite a breeze\n\n\nAfter this correction, the code did run, but ChatGPT forgot to add the frequency option, so the data y axis shows the probability of each outcome from 0 to 0.5. But the y axis labels are still set to reflect frequency. It’s not a good look!\n\n\n\n\nConclusion\nWhile ChatGPT was capable of performing the basic code translation tasks, it needed a lot of correction. It seemed to be a lot less comfortable working with Stata than with R. It’s true that R is open source and Stata isn’t, but I expected better results because Stata has been around for a long time. For reference, ChatGPT tells me that the first official version of R was released in February 2000, while Stata 1.0 was released in 1985.\nWhen pressed about its relative amounts of training data, ChatGPT did confess that it had more access to R data- though who knows if that is the truth.\n\n\nA final note: I had never before seen the Stata command that kept throwing me errors from the AI-generated responses. As far as I can tell, this command, edgecolor, is exclusively found in MATLAB syntax!"
  }
]